{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Linear Regression\n",
    "\n",
    "_Authors: Kevin Markham (DC), Ed Podojil (NYC)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Introduce the bikeshare data](#introduce-the-bikeshare-data)\n",
    "\t- [Reading in the data](#reading-in-the-data)\n",
    "\t- [Visualizing the data](#visualizing-the-data)\n",
    "- [Linear regression basics](#linear-regression-basics)\n",
    "\t- [Form of linear regression](#form-of-linear-regression)\n",
    "\t- [Building a linear regression model](#building-a-linear-regression-model)\n",
    "\t- [Using the model for prediction](#using-the-model-for-prediction)\n",
    "\t- [Does the scale of the features matter?](#does-the-scale-of-the-features-matter)\n",
    "- [Working with multiple features](#working-with-multiple-features)\n",
    "\t- [Visualizing the data (part 2)](#visualizing-the-data-part-)\n",
    "\t- [Adding more features to the model](#adding-more-features-to-the-model)\n",
    "- [What is Multicollinearity?](#what-is-multicollinearity)\n",
    "- [Choosing between models](#choosing-between-models)\n",
    "\t- [Feature selection](#feature-selection)\n",
    "\t- [Evaluation metrics for regression problems](#evaluation-metrics-for-regression-problems)\n",
    "\t- [Comparing models with train/test split and RMSE](#comparing-models-with-traintest-split-and-rmse)\n",
    "\t- [Comparing testing RMSE with null RMSE](#comparing-testing-rmse-with-null-rmse)\n",
    "- [Creating features](#creating-features)\n",
    "\t- [Handling categorical features](#handling-categorical-features)\n",
    "\t- [Feature engineering](#feature-engineering)\n",
    "- [Comparing linear regression with other models](#comparing-linear-regression-with-other-models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"introduce-the-bikeshare-data\"></a>\n",
    "## Introduce the bikeshare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"reading-in-the-data\"></a>\n",
    "<a id=\"reading-in-the-data\"></a>\n",
    "### Reading in the data\n",
    "\n",
    "We'll be working with a dataset from Capital Bikeshare that was used in a Kaggle competition ([data dictionary](https://www.kaggle.com/c/bike-sharing-demand/data))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data and set the datetime as the index\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/bikeshare.csv'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "- What does each observation represent?\n",
    "- What is the response variable (as defined by Kaggle)?\n",
    "- How many features are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"count\" is a method, so it's best to name that column something else\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visualizing-the-data\"></a>\n",
    "<a id=\"visualizing-the-data\"></a>\n",
    "### Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas scatter plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn scatter plot with regression line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"linear-regression-basics\"></a>\n",
    "## Linear regression basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"form-of-linear-regression\"></a>\n",
    "<a id=\"form-of-linear-regression\"></a>\n",
    "### Form of linear regression\n",
    "\n",
    "$y = \\alpha + \\beta X + \\epsilon$\n",
    "\n",
    "$y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n + \\epsilon$\n",
    "\n",
    "- $y$ is the response\n",
    "- $\\beta_0$ is the intercept\n",
    "- $\\beta_1$ is the coefficient for $x_1$ (the first feature)\n",
    "- $\\beta_n$ is the coefficient for $x_n$ (the nth feature)\n",
    "\n",
    "The $\\beta$ values are called the **model coefficients**:\n",
    "\n",
    "- These values are estimated (or \"learned\") during the model fitting process using the **least squares criterion**.\n",
    "- Specifically, we are find the line (mathematically) which minimizes the **sum of squared residuals** (or \"sum of squared errors\").\n",
    "- And once we've learned these coefficients, we can use the model to predict the response.\n",
    "\n",
    "![Estimating coefficients](../assets/images/estimating_coefficients.png)\n",
    "\n",
    "In the diagram above:\n",
    "\n",
    "- The black dots are the **observed values** of x and y.\n",
    "- The blue line is our **least squares line**.\n",
    "- The red lines are the **residuals**, which are the vertical distances between the observed values and the least squares line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"building-a-linear-regression-model\"></a>\n",
    "<a id=\"building-a-linear-regression-model\"></a>\n",
    "### Building a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import, instantiate, fit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the coefficients\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the **intercept** ($\\beta_0$):\n",
    "\n",
    "- It is the value of $y$ when $x$=0.\n",
    "- Thus, it is the estimated number of rentals when the temperature is 0 degrees Celsius.\n",
    "- **Note:** It does not always make sense to interpret the intercept. (Why?)\n",
    "\n",
    "Interpreting the **\"temp\" coefficient** ($\\beta_1$):\n",
    "\n",
    "- It is the change in $y$ divided by change in $x$, or the \"slope\".\n",
    "- Thus, a temperature increase of 1 degree Celsius is **associated with** a rental increase of 9.17 bikes.\n",
    "- This is not a statement of causation.\n",
    "- $\\beta_1$ would be **negative** if an increase in temperature was associated with a **decrease** in rentals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"using-the-model-for-prediction\"></a>\n",
    "<a id=\"using-the-model-for-prediction\"></a>\n",
    "### Using the model for prediction\n",
    "\n",
    "How many bike rentals would we predict if the temperature was 25 degrees Celsius?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually calculate the prediction\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the predict method\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"does-the-scale-of-the-features-matter\"></a>\n",
    "<a id=\"does-the-scale-of-the-features-matter\"></a>\n",
    "### Does the scale of the features matter?\n",
    "\n",
    "Let's say that temperature was measured in Fahrenheit, rather than Celsius. How would that affect the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column for Fahrenheit temperature\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn scatter plot with regression line\n",
    "sns.lmplot(x='temp_F', y='total', data=bikes, aspect=1.5, scatter_kws={'alpha':0.2});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# instantiate and fit\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print the coefficients\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 25 degrees Celsius to Fahrenheit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict rentals for 77 degrees Fahrenheit\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** The scale of the features is **irrelevant** for linear regression models. When changing the scale, we simply change our **interpretation** of the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the temp_F column\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"working-with-multiple-features\"></a>\n",
    "## Working with multiple features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visualizing-the-data-part-\"></a>\n",
    "<a id=\"visualizing-the-data-part-\"></a>\n",
    "### Visualizing the data (part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore more features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple scatter plots in Seaborn\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple scatter plots in Pandas\n",
    "fig, axs = plt.subplots(1, len(feature_cols), sharey=True)\n",
    "for index, feature in enumerate(feature_cols):\n",
    "    bikes.plot(kind='scatter', x=feature, y='total', ax=axs[index], figsize=(16, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are you seeing anything that you did not expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-tabulation of season and month\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plot of rentals, grouped by season\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notably:\n",
    "\n",
    "- A line can't capture a non-linear relationship.\n",
    "- There are more rentals in winter than in spring (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line plot of rentals\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this tell us?\n",
    "\n",
    "There are more rentals in the winter than the spring, but only because the system is experiencing **overall growth** and the winter months happen to come after the spring months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix (ranges from 1 to -1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize correlation matrix in Seaborn using a heatmap\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What relationships do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"adding-more-features-to-the-model\"></a>\n",
    "<a id=\"adding-more-features-to-the-model\"></a>\n",
    "### Adding more features to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, one variable explained the variance of another; however, more often than not, we will need multiple variables. \n",
    "\n",
    "- For example, a house's price may be best measured by square feet, but a lot of other variables play a vital role: bedrooms, bathrooms, location, appliances, etc. \n",
    "\n",
    "- For a linear regression, we want these variables to be largely independent of each other, but all of them should help explain the y variable.\n",
    "\n",
    "We'll work with bike-share data to showcase what this means and to explain a concept called multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# instantiate and fit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print the coefficients\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair the feature names with the coefficients\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the coefficients:\n",
    "\n",
    "- Holding all other features fixed, a 1 unit increase in **temperature** is associated with a **rental increase of 7.86 bikes**.\n",
    "- Holding all other features fixed, a 1 unit increase in **season** is associated with a **rental increase of 22.5 bikes**.\n",
    "- Holding all other features fixed, a 1 unit increase in **weather** is associated with a **rental increase of 6.67 bikes**.\n",
    "- Holding all other features fixed, a 1 unit increase in **humidity** is associated with a **rental decrease of 3.12 bikes**.\n",
    "\n",
    "Does anything look incorrect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"what-is-multicollinearity\"></a>\n",
    "<a id=\"what-is-multicollinearity\"></a>\n",
    "## What is Multicollinearity?\n",
    "\n",
    "With the bike share data, let's compare three data points: actual temperature, \"feel\" temperature, and guest ridership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "  \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y\n",
    "\n",
    "\n",
    "# instantiate and fit\n",
    "\n",
    "\n",
    "# print the coefficients\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"choosing-between-models\"></a>\n",
    "## Choosing between models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"feature-selection\"></a>\n",
    "<a id=\"feature-selection\"></a>\n",
    "### Feature selection\n",
    "\n",
    "How do we choose which features to include in the model? We're going to use **train/test split** (and eventually **cross-validation**).\n",
    "\n",
    "Why not use of **p-values** or **R-squared** for feature selection?\n",
    "\n",
    "- Linear models rely upon **a lot of assumptions** (such as the features being independent), and if those assumptions are violated, p-values and R-squared are less reliable. Train/test split relies on fewer assumptions.\n",
    "- Features that are unrelated to the response can still have **significant p-values**.\n",
    "- Adding features to your model that are unrelated to the response will always **increase the R-squared value**, and adjusted R-squared does not sufficiently account for this.\n",
    "- p-values and R-squared are **proxies** for our goal of generalization, whereas train/test split and cross-validation attempt to **directly estimate** how well the model will generalize to out-of-sample data.\n",
    "\n",
    "More generally:\n",
    "\n",
    "- There are different methodologies that can be used for solving any given data science problem, and this course follows a **machine learning methodology**.\n",
    "- This course focuses on **general purpose approaches** that can be applied to any model, rather than model-specific approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluation-metrics-for-regression-problems\"></a>\n",
    "<a id=\"evaluation-metrics-for-regression-problems\"></a>\n",
    "### Evaluation metrics for regression problems\n",
    "\n",
    "Evaluation metrics for classification problems, such as **accuracy**, are not useful for regression problems. We need evaluation metrics designed for comparing **continuous values**.\n",
    "\n",
    "Here are three common evaluation metrics for regression problems:\n",
    "\n",
    "**Mean Absolute Error** (MAE) is the mean of the absolute value of the errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n",
    "\n",
    "**Mean Squared Error** (MSE) is the mean of the squared errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "**Root Mean Squared Error** (RMSE) is the square root of the mean of the squared errors:\n",
    "\n",
    "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example true and predicted response values\n",
    "true = [10, 7, 5, 5]\n",
    "pred = [8, 6, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate these metrics by hand!\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "print('MAE:', metrics.mean_absolute_error(true, pred))\n",
    "print('MSE:', metrics.mean_squared_error(true, pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(true, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing these metrics:\n",
    "\n",
    "- **MAE** is the easiest to understand, because it's the average error.\n",
    "- **MSE** is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world.\n",
    "- **RMSE** is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n",
    "\n",
    "All of these are **loss functions**, because we want to minimize them.\n",
    "\n",
    "Here's an additional example, to demonstrate how MSE/RMSE punish larger errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same true values as above\n",
    "true = [10, 7, 5, 5]\n",
    "\n",
    "# new set of predicted values\n",
    "pred = [10, 7, 5, 13]\n",
    "\n",
    "# MAE is the same as before\n",
    "print('MAE:', metrics.mean_absolute_error(true, pred))\n",
    "\n",
    "# MSE and RMSE are larger than before\n",
    "print('MSE:', metrics.mean_squared_error(true, pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(true, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comparing-models-with-traintest-split-and-rmse\"></a>\n",
    "<a id=\"comparing-models-with-traintest-split-and-rmse\"></a>\n",
    "### Comparing models with train/test split and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# define a function that accepts a list of features and returns testing RMSE\n",
    "def train_test_rmse(feature_cols):\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare different sets of features\n",
    "print(train_test_rmse(['temp', 'season', 'weather', 'humidity']))\n",
    "print(train_test_rmse(['temp', 'season', 'weather']))\n",
    "print(train_test_rmse(['temp', 'season', 'humidity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Try out as many combinations of features as you can to evaluate train_test_rmse\n",
    "\n",
    "Tips:\n",
    "- look at the combinations package in itertools: https://docs.python.org/2/library/itertools.html#itertools.combinations\n",
    "- think about if there are any features you should not include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "features = [col for col in bikes.columns if col not in (['total','casual','registered'])]\n",
    "\n",
    "results = []\n",
    "for i in range(1,len(features)):\n",
    "    for feature_combo in combinations(features, i):\n",
    "        rmse = train_test_rmse(list(feature_combo))\n",
    "        results.append([feature_combo, rmse])\n",
    "    \n",
    "result = pd.DataFrame(results, columns=['features','rmse']).sort_values('rmse')\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comparing-testing-rmse-with-null-rmse\"></a>\n",
    "<a id=\"comparing-testing-rmse-with-null-rmse\"></a>\n",
    "### Comparing testing RMSE with null RMSE\n",
    "\n",
    "Null RMSE is the RMSE that could be achieved by **always predicting the mean response value**. It is a benchmark against which you may want to measure your regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using these as features is not allowed!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a NumPy array with the same shape as y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the array with the mean value of y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute null RMSE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"creating-features\"></a>\n",
    "## Creating features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"handling-categorical-features\"></a>\n",
    "<a id=\"handling-categorical-features\"></a>\n",
    "### Handling categorical features\n",
    "\n",
    "scikit-learn expects all features to be numeric. So how do we include a categorical feature in our model?\n",
    "\n",
    "- **Ordered categories:** transform them to sensible numeric values (example: small=1, medium=2, large=3)\n",
    "- **Unordered categories:** use dummy encoding (0/1)\n",
    "\n",
    "What are the categorical features in our dataset?\n",
    "\n",
    "- **Ordered categories:** weather (already encoded with sensible numeric values)\n",
    "- **Unordered categories:** season (needs dummy encoding), holiday (already dummy encoded), workingday (already dummy encoded)\n",
    "\n",
    "For season, we can't simply leave the encoding as 1 = spring, 2 = summer, 3 = fall, and 4 = winter, because that would imply an **ordered relationship**. Instead, we create **multiple dummy variables:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy variables\n",
    "\n",
    "\n",
    "# print 5 random rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we actually only need **three dummy variables (not four)**, and thus we'll drop the first dummy variable.\n",
    "\n",
    "Why? Because three dummies captures all of the \"information\" about the season feature, and implicitly defines spring (season 1) as the **baseline level:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the first column\n",
    "\n",
    "\n",
    "# print 5 random rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, if you have a categorical feature with **k possible values**, you create **k-1 dummy variables**.\n",
    "\n",
    "If that's confusing, think about why we only need one dummy variable for holiday, not two dummy variables (holiday_yes and holiday_no)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the original DataFrame and the dummy DataFrame (axis=0 means rows, axis=1 means columns)\n",
    "\n",
    "\n",
    "# print 5 random rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include dummy variables for season in the model\n",
    "feature_cols = ['temp', 'season_2', 'season_3', 'season_4', 'humidity']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we interpret the season coefficients? They are **measured against the baseline (spring)**:\n",
    "\n",
    "- Holding all other features fixed, **summer** is associated with a **rental decrease of 3.39 bikes** compared to the spring.\n",
    "- Holding all other features fixed, **fall** is associated with a **rental decrease of 41.7 bikes** compared to the spring.\n",
    "- Holding all other features fixed, **winter** is associated with a **rental increase of 64.4 bikes** compared to the spring.\n",
    "\n",
    "Would it matter if we changed which season was defined as the baseline?\n",
    "\n",
    "- No, it would simply change our **interpretation** of the coefficients.\n",
    "\n",
    "**Important:** Dummy encoding is relevant for all machine learning models, not just linear regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare original season variable with dummy variables\n",
    "print(train_test_rmse(['temp', 'season', 'humidity']))\n",
    "print(train_test_rmse(['temp', 'season_2', 'season_3', 'season_4', 'humidity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"feature-engineering\"></a>\n",
    "<a id=\"feature-engineering\"></a>\n",
    "### Feature engineering\n",
    "\n",
    "See if you can create the following features:\n",
    "\n",
    "- **hour:** as a single numeric feature (0 through 23)\n",
    "- **hour:** as a categorical feature (use 23 dummy variables)\n",
    "- **daytime:** as a single categorical feature (daytime=1 from 7am to 8pm, and daytime=0 otherwise)\n",
    "\n",
    "Then, try using each of the three features (on its own) with `train_test_rmse` to see which one performs the best!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hour as a numeric feature (look at the index)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hour as a categorical feature\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daytime as a categorical feature\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_test_rmse(['hour']))\n",
    "print(train_test_rmse(bikes.columns[bikes.columns.str.startswith('hour_')]))\n",
    "print(train_test_rmse(['daytime']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comparing-linear-regression-with-other-models\"></a>\n",
    "<a id=\"comparing-linear-regression-with-other-models\"></a>\n",
    "## Comparing linear regression with other models\n",
    "\n",
    "Advantages of linear regression:\n",
    "\n",
    "- Simple to explain\n",
    "- Highly interpretable\n",
    "- Model training and prediction are fast\n",
    "- No tuning is required (excluding regularization)\n",
    "- Features don't need scaling\n",
    "- Can perform well with a small number of observations\n",
    "- Well-understood\n",
    "\n",
    "Disadvantages of linear regression:\n",
    "\n",
    "- Presumes a linear relationship between the features and the response\n",
    "- Performance is (generally) not competitive with the best supervised learning methods due to high bias\n",
    "- Can't automatically learn feature interactions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
