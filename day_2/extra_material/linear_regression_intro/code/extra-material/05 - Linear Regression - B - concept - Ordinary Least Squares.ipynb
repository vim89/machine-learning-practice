{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://s-media-cache-ak0.pinimg.com/564x/fe/aa/1a/feaa1a16a315823b2d9ad24da7eccdaf.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       "@font-face {\n",
       "    font-family: 'Cooper Hewit' ;\n",
       "    src: url(utils/CooperHewitt-Medium.otf);\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "    font-family: 'Cooper Hewit Bold' ;\n",
       "    src: url(utils/CooperHewitt-Bold.otf);\n",
       "}\n",
       "\n",
       "@font-face {\n",
       "    font-family: 'Cooper Hewit Light' ;\n",
       "    src: url(utils/CooperHewitt-Light.otf);\n",
       "}\n",
       "\n",
       ".container {\n",
       "    width:96% !important;\n",
       "    font-family: 'Cooper Hewit','Source Sans Pro', 'Open Sans', 'Helvetica', Sans;\n",
       "}\n",
       "\n",
       ".text_cell_render h1 {\n",
       "    text-align: center;\n",
       "    font-family: 'Cooper Hewit Light';\n",
       "    font-size: 52px;\n",
       "}\n",
       "\n",
       "h2, h3 {\n",
       "    font-family: 'Cooper Hewit Bold' ;\n",
       "}\n",
       "\n",
       ".rendered_html strong {\n",
       "    font-family: 'Cooper Hewit Bold' ; \n",
       "    font-weight: bold;\n",
       "}\n",
       "\n",
       ".text_cell_render p,\n",
       ".text_cell_render h2,\n",
       ".text_cell_render h3,\n",
       ".text_cell_render h4,\n",
       ".text_cell_render ul,\n",
       ".text_cell_render ol,\n",
       ".text_cell_render table,\n",
       ".text_cell_render pre {\n",
       "    max-width: 860px;\n",
       "    margin: 0 auto;\n",
       "    line-height: 30px;\n",
       "}\n",
       "\n",
       ".text_cell_render p,\n",
       ".text_cell_render ul,\n",
       ".text_cell_render ol,\n",
       ".text_cell_render table {\n",
       "    font-family: 'Cooper Hewit' ;\n",
       "    font-size: 20px;\n",
       "    padding-bottom : 26px;\n",
       "}\n",
       "\n",
       ".text_cell_render h4 {\n",
       "    font-size: 20px;\n",
       "    text-align: center;\n",
       "}\n",
       "\n",
       ".rendered_html pre,\n",
       ".rendered_html code {\n",
       "    font-size: 20px;\n",
       "    line-height: 30px;\n",
       "    background-color: #f9f9f9;\n",
       "    padding: 8px;\n",
       "}\n",
       "\n",
       ".rendered_html code:not(.cm-s-ipython) {\n",
       "    padding: 0;\n",
       "    padding-top: 0.2em;\n",
       "    padding-bottom: 0.2em;\n",
       "    margin: 0;\n",
       "    background-color: rgba(0, 0, 0, 0.04);\n",
       "    border-radius: 3px;\n",
       "}\n",
       "\n",
       ".text_cell.rendered .input_prompt {\n",
       "    display : none !important;\n",
       "}\n",
       "\n",
       ".text_cell_render table {\n",
       "    width: 860px;\n",
       "    margin: 26px auto;\n",
       "    text-align: center;\n",
       "}\n",
       "\n",
       ".text_cell_render td,\n",
       ".text_cell_render th {\n",
       "    padding: 8px;\n",
       "    text-align: center;\n",
       "}\n",
       "\n",
       ".text_cell_render table thead {\n",
       "    background-color: #333;\n",
       "    color: white;\n",
       "    font-family: 'Cooper Hewit Light';\n",
       "    text-align: center;\n",
       "}\n",
       "\n",
       ".CodeMirror {\n",
       "    padding: 8px 20px;\n",
       "}\n",
       ".CodeMirror pre {\n",
       "    font-size: 20px;\n",
       "    line-height: 28px;\n",
       "}\n",
       "\n",
       "div.output_text pre {\n",
       "    color: #333;\n",
       "    font-size: 18px;\n",
       "    line-height: 26px;\n",
       "}\n",
       ".output_png img{\n",
       "    margin: 0 auto;\n",
       "    margin-top: 12px;\n",
       "    display: block;\n",
       "    min-width: 600px;\n",
       "}\n",
       "\n",
       ".rendered_html blockquote cite:before {\n",
       "    content: '— ';\n",
       "}\n",
       ".rendered_html blockquote p:before {\n",
       "    content: \"“\";\n",
       "    font-size: 160px;\n",
       "    color: rgba(218, 218, 218, 0.68);\n",
       "    position: relative;\n",
       "    margin-left: -72px;\n",
       "    top: 32px;\n",
       "    left: 37px;\n",
       "    font-family: Cooper Hewitt Bold;\n",
       "    z-index: 0;\n",
       "}\n",
       ".rendered_html blockquote {\n",
       "    clear: both;\n",
       "    border: none;\n",
       "}\n",
       "\n",
       ".rendered_html blockquote p:after {\n",
       "    visibility: hidden;\n",
       "    display: block;\n",
       "    content: \"\";\n",
       "    clear: both;\n",
       "    height: 0;\n",
       "\n",
       "}\n",
       "\n",
       ".rendered_html blockquote cite {\n",
       "    display: block;\n",
       "    padding-left: 30%;\n",
       "    padding-right: 10%;\n",
       "    text-align: right;\n",
       "    margin-top: 12px;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load utils/imports.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *\n",
    "from utils.plotting import *\n",
    "\n",
    "from utils.styles import *\n",
    "\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few major uses for regression analysis:\n",
    "\n",
    "1. correlation analysis - determining if $X$ is correlated with $y$.\n",
    "1. forecasting an effect - predicting if a change in $X$ will also change $y$.\n",
    "1. trend forecasting - determining if changes in $X$ are causing $y$ to trend in a certain direction.\n",
    "1. influence analysis - determining the strength of relationships between two or more varibles or correlated relationships between one or more independent and one dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Visual Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the simplest ways to fit a model to a set of training data is a linear function that attempts to fit a line to a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://setosa.io/ev/ordinary-least-squares-regression/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f43902b8668>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='http://setosa.io/ev/ordinary-least-squares-regression/', width='100%', height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Gentle Introduction with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Scikit-learn this can be accomplished using the `LinearRegression` linear model. In these models your input features are typically referred to as $X$ and your target is $y$.\n",
    "\n",
    "To begin, let's create a trivial example to show how this works. We will create a set of training points `(10, 10)`, `(20, 20)`, `(30, 30)` and a set of test points that fall on the same line. `LinearRegression` should find and fit this line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/io/.tools/anaconda/envs/vdl/lib/python3.5/site-packages/cufflinks/plotlytools.py:164: FutureWarning:\n",
      "\n",
      "The pandas.stats.ols module is deprecated and will be removed in a future version. We refer to external packages like statsmodels, see some examples here: http://statsmodels.sourceforge.net/stable/regression.html\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"f2ba99d0-f7a4-4c5a-8add-e12f9a004da1\" style=\"height: 720px; width: 980px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"f2ba99d0-f7a4-4c5a-8add-e12f9a004da1\", [{\"type\": \"scatter\", \"y\": [15, 25, 35], \"line\": {\"color\": \"rgba(247, 205, 148, 1.0)\", \"width\": 1.3, \"dash\": \"solid\"}, \"marker\": {\"size\": 12, \"symbol\": \"dot\"}, \"text\": \"\", \"name\": \"X\", \"x\": [15, 25, 35], \"mode\": \"markers\"}, {\"type\": \"scatter\", \"y\": [15.000000000000004, 24.999999999999993, 34.999999999999986], \"line\": {\"color\": \"rgba(247, 148, 170, 1.0)\", \"width\": 3, \"dash\": \"dash\"}, \"name\": \"10.00*x+5.00\", \"x\": [15, 25, 35], \"mode\": \"lines\"}], {\"width\": 980, \"height\": 720, \"plot_bgcolor\": \"#FFFFFF\", \"title\": \"Estimation with LinearRegression\", \"xaxis1\": {\"tickfont\": {\"color\": \"#4D5663\"}, \"showgrid\": true, \"gridcolor\": \"#E1E5ED\", \"title\": \"\", \"zerolinecolor\": \"#E1E5ED\", \"titlefont\": {\"color\": \"#4D5663\"}}, \"legend\": {\"bgcolor\": \"#FFFFFF\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#FFFFFF\", \"yaxis1\": {\"tickfont\": {\"color\": \"#4D5663\"}, \"showgrid\": true, \"gridcolor\": \"#E1E5ED\", \"title\": \"\", \"zerolinecolor\": \"#E1E5ED\", \"titlefont\": {\"color\": \"#4D5663\"}}, \"titlefont\": {\"color\": \"#4D5663\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0\n",
      "Root Mean Squared Error: 0.0\n",
      "Variance Score: 1.0\n",
      "Coefficients: [[ 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def lin_reg(X_train, y_train, X_test, y_test, graph=True, normalize=False):\n",
    "    regr = LinearRegression(normalize=normalize)\n",
    "    regr.fit(X_train, y_train)\n",
    "    predictions = regr.predict(X_test)\n",
    "\n",
    "    \n",
    "    if graph:\n",
    "        # Graphing with Plotly via Cufflinks\n",
    "        df = pd.concat([X_test, y_test],axis=1,)\n",
    "        df.columns = ['X','y']\n",
    "        df.set_index('y').iplot(\n",
    "            mode=\"markers\",\n",
    "            title=\"Estimation with LinearRegression\",\n",
    "            bestfit=True,\n",
    "            colors=['#F7CD94'],\n",
    "            bestfit_colors=['#F794AA'],\n",
    "            error_type='data')\n",
    "    \n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    print('Mean Squared Error: {:.2}'.format(mse))\n",
    "    print('Root Mean Squared Error: {:.2}'.format(np.sqrt(mse)))\n",
    "    print('Variance Score: {:.2}'.format(regr.score(X_test, y_test)))\n",
    "    print('Coefficients:', regr.coef_)\n",
    "    \n",
    "    return regr\n",
    "\n",
    "X_train = pd.DataFrame([10, 20, 30])\n",
    "y_train = pd.DataFrame([10, 20, 30])\n",
    "X_test = pd.DataFrame([15, 25, 35])\n",
    "y_test = pd.DataFrame([15, 25, 35])\n",
    "\n",
    "model = lin_reg(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the line was a perfect fit for our test data points. Notice that we printed a few other pieces of information here:\n",
    "\n",
    "#### Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textrm{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (prediction_i - actual_i)^2$$\n",
    "\n",
    "MSE is a measure of the error between the predicted points and the actual results. Essentially this means that for each predicted point we compute the Euclidean distance from it to the actual point, square that value, sum all the squared values together, and finally divide by the number of points to get the mean or average.\n",
    "\n",
    "For this simple example, we had no error. This is not typical of real datasets!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\textrm{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (prediction_i - actual_i)^2}$$\n",
    "\n",
    "RMSE is simply the square root of the MSE. The big difference between from MSE is that RMSE severely punishes large errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root Mean Squared Logarithmic Error (RMSLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$RMSLE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (\\log(prediction_i + 1) - \\log(actual_i+1))^2 }$$\n",
    "\n",
    "RMSLE is very similar to RMSE, but uses the natural log value of your prediction and actual results. This results in a metric that penalizes an under-predicted estimate greater than an over-predicted estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance Score ($R^2$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance score is also known as the coefficient of determination and typically denoted as $R^2$ and pronounced R-squared. One advantage of $R^2$ is that it is typically scaled between 0 and 1, but it can be negative in a model without an intercept. Typically, the closer to 1 you are, the better your model predicts the data. This allows it to be more easily interpreted than MSE. However, the downside is that it is more difficult to tell how much predictions deviate, on average, from the actual values in the dataset.\n",
    "\n",
    "$R^2$ is a useful and intuitive metric, but it can be [misleading](http://blog.minitab.com/blog/adventures-in-statistics/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit). Low scores are not inherently bad and high scores cannot be presumed to be good. You should generally evaluate $R^2$ values in conjunction with residual plots, other model statistics, and knowledge of your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand what $R^2$ represents it's good to know what baseline you are comparing it agains - this baseline is the best possible guess _without_ the aid of a model. This value is known as the _expected_ valye, and you would know it as the _mean_. $R^2$ is based on the following three _(S)um of (S)quares_:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$SST = \\Sigma(y_i-\\bar{y})^2$$\n",
    "$$SSR = \\Sigma(\\hat{y}_i-\\bar{y})^2$$\n",
    "$$SSE = \\Sigma(y_i-\\hat{y})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/total-regression-error-sum-of-squares.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are explained as :\n",
    "* $SST$ = Total Sum of Squared Deviations in $y$ from its mean $\\hat{y}$\n",
    "* $SSR$ = Sum of squares due to regression\n",
    "* $SSE$ = Sum of Squared Residiuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $R^2$ finally is defined as \n",
    "\n",
    "$$R = 1 - \\frac{SSE}{SST}$$\n",
    "\n",
    "So a good way of thinking about $R^2$ is how much of the _total_ variance in the data is explained by your model explains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression coefficients represent the mean change in the response variable for one unit of change in the predictor variable while holding other predictors in the model constant. This statistical control that regression provides is important because it isolates the role of one variable from all of the others in the model.\n",
    "\n",
    "The key to understanding the coefficients is to think of them as slopes, and they’re often called slope coefficients. In our example above we can see that there is one coefficient for our single feature and it has a value of $1.0$. This indicates that for every change of $1$ in $X$ we get a change of $1$ in $y$, which is exactly what our line shows.\n",
    "\n",
    "Coefficients can be useful in assessing which of your features have the most profound effect on your model. Coefficients that have a higher absolute value typically indicate a greater influence on your model while those with a lower absolute value influence your model less - provided that they are of the same scale!\n",
    "\n",
    "Interpretting coefficients can be quite tricky though and more detailed explanations are beyond the scope of this session. If you are interested in more, here are a few resources to help you along:\n",
    "\n",
    "* [Interpreting Regression Coefficients](http://www.theanalysisfactor.com/interpreting-regression-coefficients/)\n",
    "* [How to Interpret Regression Analysis Results: P-values and Coefficients](http://blog.minitab.com/blog/adventures-in-statistics/how-to-interpret-regression-analysis-results-p-values-and-coefficients)\n",
    "* [Common Mistakes in Interpretation of Regression Coefficients](https://www.ma.utexas.edu/users/mks/statmistakes/regressioncoeffs.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUIZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What values are we looking for when we consider $SSE$? What is the best value we could potentially have?\n",
    "1. What is the best value we could have for $R^2$ ?\n",
    "1. What’s the primary difference between these two values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing the Inevitable Errros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try another example that adds a little noise to our input values so we can see how this affects the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/io/.tools/anaconda/envs/vdl/lib/python3.5/site-packages/cufflinks/plotlytools.py:164: FutureWarning:\n",
      "\n",
      "The pandas.stats.ols module is deprecated and will be removed in a future version. We refer to external packages like statsmodels, see some examples here: http://statsmodels.sourceforge.net/stable/regression.html\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"3ba95ec3-540e-40c9-a2dc-c19fe86de227\" style=\"height: 720px; width: 980px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"3ba95ec3-540e-40c9-a2dc-c19fe86de227\", [{\"type\": \"scatter\", \"y\": [20, 28, 39], \"line\": {\"color\": \"rgba(247, 205, 148, 1.0)\", \"width\": 1.3, \"dash\": \"solid\"}, \"marker\": {\"size\": 12, \"symbol\": \"dot\"}, \"text\": \"\", \"name\": \"X\", \"x\": [15, 25, 35], \"mode\": \"markers\"}, {\"type\": \"scatter\", \"y\": [19.500000000000004, 28.999999999999993, 38.499999999999986], \"line\": {\"color\": \"rgba(247, 148, 170, 1.0)\", \"width\": 3, \"dash\": \"dash\"}, \"name\": \"9.50*x+10.00\", \"x\": [15, 25, 35], \"mode\": \"lines\"}], {\"width\": 980, \"height\": 720, \"plot_bgcolor\": \"#FFFFFF\", \"title\": \"Estimation with LinearRegression\", \"xaxis1\": {\"tickfont\": {\"color\": \"#4D5663\"}, \"showgrid\": true, \"gridcolor\": \"#E1E5ED\", \"title\": \"\", \"zerolinecolor\": \"#E1E5ED\", \"titlefont\": {\"color\": \"#4D5663\"}}, \"legend\": {\"bgcolor\": \"#FFFFFF\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#FFFFFF\", \"yaxis1\": {\"tickfont\": {\"color\": \"#4D5663\"}, \"showgrid\": true, \"gridcolor\": \"#E1E5ED\", \"title\": \"\", \"zerolinecolor\": \"#E1E5ED\", \"titlefont\": {\"color\": \"#4D5663\"}}, \"titlefont\": {\"color\": \"#4D5663\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.6\n",
      "Root Mean Squared Error: 0.77\n",
      "Variance Score: 0.99\n",
      "Coefficients: [[ 1.04395604]]\n"
     ]
    }
   ],
   "source": [
    "def make_some_noise(seed):\n",
    "    np.random.seed(seed)\n",
    "    return pd.DataFrame(np.random.randint(0, 7, size=(3, 1)))\n",
    "\n",
    "X_noise = make_some_noise(1)\n",
    "X_train_noisy = X_train + X_noise\n",
    "X_test_noisy = X_test + X_noise\n",
    "\n",
    "_ = lin_reg(X_train_noisy, y_train, X_test_noisy, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "We can see that with a little noise on our inputs we still get good results, but we are no longer able to make perfect predictions. This is an important point because noise is very common in real data. It is possible to have noise on your input feature values, on your target values, and often on both!\n",
    "\n",
    "Noise can come from many places. A few common examples include:\n",
    "- Sensor error - sensor readings aren't always perfect.\n",
    "- Malicious error - intentionally bad datasets.\n",
    "- Transcription error - someone makes a mistake recording data.\n",
    "- Unmodeled influences - you may not account for all features or you may account for the wrong features. For example, if you only look at price you can't make a great prediction about how stocks will move in the market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
