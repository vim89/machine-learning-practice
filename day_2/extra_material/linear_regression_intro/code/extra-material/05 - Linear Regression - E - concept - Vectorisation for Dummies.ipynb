{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://s-media-cache-ak0.pinimg.com/564x/fe/aa/1a/feaa1a16a315823b2d9ad24da7eccdaf.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load utils/imports.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *\n",
    "from utils.plotting import *\n",
    "\n",
    "from utils.demo import *\n",
    "from utils.styles import *\n",
    "\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorisation for Dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem that you may commonly encounter is that some datasets contain columns that aren't numeric. Often there will be named categories in your datasets and linear regression won't work on these out of the box. In order to deal with this we can use a technique called vectorisation. This is the process of converting a single column of categories to one column per category where a 1 indicates that the column is of that type and a 0 indicates that the column is not of that type.\n",
    "\n",
    "We'll use the famous [Iris dataset](http://archive.ics.uci.edu/ml/datasets/Iris) to illustrate vectorisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset(\"iris\")\n",
    "grid(iris.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to use linear regression to predict the the sepal length with our current features, we will get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "iris_train, iris_test = train_test_split(iris)\n",
    "X_train = iris_train.drop(['sepal_length'], axis=1)\n",
    "X_test = iris_test.drop(['sepal_length'], axis=1)\n",
    "y_train = iris_train[['sepal_length']]\n",
    "y_test = iris_test[['sepal_length']]\n",
    "\n",
    "try:\n",
    "    regr = lin_reg(X_train, y_train, X_test, y_test, graph=False, normalize=True)\n",
    "except ValueError as e:\n",
    "    print(\"ValueError :\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummies to the rescue!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(iris[\"species\"])\n",
    "# Add to the original dataframe\n",
    "iris_with_dummies = pd.concat([iris, dummies], axis=1)\n",
    "grid(iris_with_dummies.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_train, iris_test = train_test_split(iris_with_dummies)\n",
    "\n",
    "X_train = iris_train.drop(['sepal_length', 'species'], axis=1)\n",
    "X_test = iris_test.drop(['sepal_length', 'species'], axis=1)\n",
    "y_train = iris_train[['sepal_length']]\n",
    "y_test = iris_test[['sepal_length']]\n",
    "\n",
    "regr = lin_reg(X_train, y_train, X_test, y_test, graph=False, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummies are great, but scikit-learn provides some tools that make life even easier! Scikit-learn's ```LabelEncoder``` helps us fit and transform labels in order to normalize them to a set of numbers from 0 to $N$ where $N$ is the number of unique lables in your dataset. It also remembers the encoding so that you can retrieve the inverse of encoded values later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "colors = ['red', 'green', 'blue', 'red', 'red', 'green']\n",
    "print(\"Before:\", colors)\n",
    "le = LabelEncoder()\n",
    "le.fit(colors)\n",
    "labels = le.transform(colors)\n",
    "print(\"After:\", labels)\n",
    "inverse = le.inverse_transform(labels)\n",
    "print(\"Inverse:\", inverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, label encoding is often not sufficient by itself. If we were to simply use the labels as-is we would be imparting the ordinal property to the variable. In this case, we would be saying that since ```blue = 0, green = 1, and red = 2``` this implies that ```red > green > blue```. Sometimes this is what you want, but often when dealing with categories it is a misleading interpretation of the data.\n",
    "\n",
    "In order to avoid imparting an ordinal property, we must also make use of another encoding scheme from scikit-learn called the ```OneHotEncoder```. First, we need to convert our labels to an array-like shape using Numpy's ```vstack```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "label_array =  np.vstack(labels)\n",
    "print(\"Before:\\n\", label_array)\n",
    "enc = OneHotEncoder()\n",
    "result = enc.fit_transform(label_array)\n",
    "print(\"After:\\n\", result.toarray())"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {
    "52764b3a8c50492ab816ed12d659a25d": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "53c2896819c14d38b4b439216a92dc52": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "b85304647b6c4d95bc9f4a16d297061c": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "be6c4e2295f244f48fa2df74f67f2468": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    },
    "d9d6a3bc4748469894f224dc83315930": {
     "views": [
      {
       "cell_index": 15
      }
     ]
    },
    "f8802ba1146245fc98453efdba0c189c": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
